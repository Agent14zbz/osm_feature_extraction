{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import osmnx as ox\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_poi_query(north, south, east, west, key = None,values = None, timeout=180, maxsize='',\n",
    "                    custom_settings=None):\n",
    "    '''\n",
    "    仿写osmnx\n",
    "    根据输入key、values、四边界，返回OverpassAPI的query字符串\n",
    "    '''\n",
    "    # use custom settings if delivered, otherwise just the default ones.\n",
    "    if custom_settings:\n",
    "        overpass_settings = custom_settings\n",
    "    else:\n",
    "        overpass_settings = ox.settings.default_overpass_query_settings.format(timeout=timeout, maxsize=maxsize)\n",
    "\n",
    "    if key and values:\n",
    "        # Overpass QL template\n",
    "        query_template = ('{settings};((node[\"{key}\"~\"{values}\"]({south:.6f},'\n",
    "                          '{west:.6f},{north:.6f},{east:.6f});(._;>;););(way[\"{key}\"~\"{values}\"]({south:.6f},'\n",
    "                          '{west:.6f},{north:.6f},{east:.6f});(._;>;););(relation[\"{key}\"~\"{values}\"]'\n",
    "                          '({south:.6f},{west:.6f},{north:.6f},{east:.6f});(._;>;);););out;')\n",
    "\n",
    "        # Parse amenties\n",
    "        query_str = query_template.format(key=key,values=\"|\".join(values), north=north, south=south, east=east, west=west,timeout=timeout, maxsize=maxsize, settings=overpass_settings)\n",
    "    else:\n",
    "        # Overpass QL template\n",
    "        query_template = ('{settings};((node[\"amenity\"]({south:.6f},'\n",
    "                          '{west:.6f},{north:.6f},{east:.6f});(._;>;););(way[\"amenity\"]({south:.6f},'\n",
    "                          '{west:.6f},{north:.6f},{east:.6f});(._;>;););(relation[\"amenity\"]'\n",
    "                          '({south:.6f},{west:.6f},{north:.6f},{east:.6f});(._;>;);););out;')\n",
    "\n",
    "        # Parse amenties\n",
    "        query_str = query_template.format(north=north, south=south, east=east, west=west,\n",
    "                                          timeout=timeout, maxsize=maxsize, settings=overpass_settings)\n",
    "    return query_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_POI_gdf(north, south, east, west, key = None,values = None,custom_settings=None,timeout=180):\n",
    "    '''\n",
    "    仿写osmnx\n",
    "    从OverpassAPI获取response，并解析nodes ways relations，返回全部POI的GeoDataFrame\n",
    "    '''\n",
    "    query = get_poi_query(north=north,south=south,east=east,west=west,key=key,values=values,\n",
    "                                custom_settings=custom_settings)\n",
    "#     print(query)\n",
    "    responses = ox.overpass_request(data={'data': query}, timeout=timeout)\n",
    "    # Parse coordinates from all the nodes in the response\n",
    "    coords = ox.parse_nodes_coords(responses)\n",
    "\n",
    "    # POI nodes\n",
    "    poi_nodes = {}\n",
    "\n",
    "    # POI ways\n",
    "    poi_ways = {}\n",
    "\n",
    "    # A list of POI relations\n",
    "    relations = []\n",
    "\n",
    "    for result in responses['elements']:\n",
    "        if result['type'] == 'node' and 'tags' in result:\n",
    "            poi = ox.parse_osm_node(response=result)\n",
    "            # Add element_type\n",
    "            poi['element_type'] = 'node'\n",
    "            # Add to 'pois'\n",
    "            poi_nodes[result['id']] = poi\n",
    "        elif result['type'] == 'way':\n",
    "            # Parse POI area Polygon\n",
    "            poi_area = ox.parse_polygonal_poi(coords=coords, response=result)\n",
    "            if poi_area:\n",
    "                # Add element_type\n",
    "                poi_area['element_type'] = 'way'\n",
    "                # Add to 'poi_ways'\n",
    "                poi_ways[result['id']] = poi_area\n",
    "\n",
    "        elif result['type'] == 'relation':\n",
    "            # Add relation to a relation list (needs to be parsed after all nodes and ways have been parsed)\n",
    "            relations.append(result)\n",
    "\n",
    "    # Create GeoDataFrames\n",
    "    gdf_nodes = gpd.GeoDataFrame(poi_nodes).T\n",
    "    gdf_nodes.crs = ox.settings.default_crs\n",
    "\n",
    "    gdf_ways = gpd.GeoDataFrame(poi_ways).T\n",
    "    gdf_ways.crs = ox.settings.default_crs\n",
    "\n",
    "    # Parse relations (MultiPolygons) from 'ways'\n",
    "    gdf_ways = ox.parse_osm_relations(relations=relations, osm_way_df=gdf_ways)\n",
    "\n",
    "    # Combine GeoDataFrames\n",
    "    gdf = gdf_nodes.append(gdf_ways, sort=False)\n",
    "\n",
    "    return gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_retail_format_data(INPUT_CSV):\n",
    "    '''\n",
    "    输入校园POI的csv文件，依次获取餐饮、零售、生活服务、休闲娱乐4类业态数量和各自占比，返回DataFrame\n",
    "    '''\n",
    "    starttime = time.time()\n",
    "    catering = {'key':'amenity', 'values':['restaurant','fast_food','bbq','bar','pub','food_court']}\n",
    "    shopping = {'key':'shop', 'values':['convenience','supermarket','dairy','bakery','confectionery','coffee','chocolate','ice_cream',\n",
    "                                        'greengrocer','craft','stationery','book','newsagent']}\n",
    "    service1 = {'key':'shop', 'values':['hairdresser','copyshop','laundry','dry_cleaning','optician','bicycle']}\n",
    "    service2 = {'key':'amenity', 'values':['bicycle_repair_station','bicycle_rental','clinic','dentist','pharmacy','hospital']}\n",
    "    leisure1 = {'key':'amenity', 'values':['library','theatre','cinema','arts_centre','internet_cafe']}\n",
    "    leisure2 = {'key':'leisure', 'values':['fitness_centre','fitness_station']}\n",
    "    leisure3 = {'key':'tourism', 'values':['museum','gallery']}\n",
    "    \n",
    "    campus = pd.read_csv(INPUT_CSV,encoding='UTF-8')\n",
    "    data_stack = []\n",
    "    for i in range(len(campus)):\n",
    "        osmid = campus.iloc[i]['OSMID']\n",
    "        length_lat = campus.iloc[i]['north']-campus.iloc[i]['south']\n",
    "        width_lon = campus.iloc[i]['east']-campus.iloc[i]['west']\n",
    "        bbox_north = campus.iloc[i]['north']+length_lat\n",
    "        bbox_south = campus.iloc[i]['south']-length_lat\n",
    "        bbox_east = campus.iloc[i]['east']+width_lon\n",
    "        bbox_west = campus.iloc[i]['west']-width_lon\n",
    "        \n",
    "        catering_gdf = create_POI_gdf(north=bbox_north,south=bbox_south,east=bbox_east,west=bbox_west,key=catering['key'],values=catering['values'])\n",
    "        shopping_gdf = create_POI_gdf(north=bbox_north,south=bbox_south,east=bbox_east,west=bbox_west,key=shopping['key'],values=shopping['values'])\n",
    "        service1_gdf = create_POI_gdf(north=bbox_north,south=bbox_south,east=bbox_east,west=bbox_west,key=service1['key'],values=service1['values'])\n",
    "        service2_gdf = create_POI_gdf(north=bbox_north,south=bbox_south,east=bbox_east,west=bbox_west,key=service2['key'],values=service2['values'])\n",
    "        leisure1_gdf = create_POI_gdf(north=bbox_north,south=bbox_south,east=bbox_east,west=bbox_west,key=leisure1['key'],values=leisure1['values'])\n",
    "        leisure2_gdf = create_POI_gdf(north=bbox_north,south=bbox_south,east=bbox_east,west=bbox_west,key=leisure2['key'],values=leisure2['values'])\n",
    "        leisure3_gdf = create_POI_gdf(north=bbox_north,south=bbox_south,east=bbox_east,west=bbox_west,key=leisure3['key'],values=leisure3['values'])\n",
    "        \n",
    "        num_catering = len(catering_gdf)\n",
    "        num_shopping = len(shopping_gdf)\n",
    "        num_service = len(service1_gdf)+len(service2_gdf)\n",
    "        num_leisure = len(leisure1_gdf)+len(leisure2_gdf)+len(leisure3_gdf)\n",
    "        num_sum = num_catering + num_shopping + num_service + num_leisure\n",
    "        if num_sum != 0:\n",
    "            data_stack.append([osmid,num_sum,num_catering,num_shopping,num_service,num_leisure,\n",
    "                        num_catering/num_sum,num_shopping/num_sum,num_service/num_sum,num_leisure/num_sum])\n",
    "        else:\n",
    "            data_stack.append([osmid,num_sum,num_catering,num_shopping,num_service,num_leisure,0,0,0,0])\n",
    "        if (i-1)%50==0:\n",
    "            print(i,' data parsed')\n",
    "    endtime = time.time()\n",
    "    print('step total time:', round(endtime - starttime, 2),'secs')\n",
    "    print('retail format data parsed!')\n",
    "    return pd.DataFrame(data_stack,columns=['OSMID','sum','catering','shopping','service','leisure','ratio_catering','ratio_shopping','ratio_service','ratio_leisure'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
